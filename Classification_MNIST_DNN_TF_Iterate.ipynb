{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Classification_MNIST_DNN_TF_Iterate.ipynb","provenance":[{"file_id":"18DXNrIxXIuTnVLs6xG3oUWaDuBObiCWA","timestamp":1569149800989}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7Dzdup9KW8yU","colab_type":"text"},"source":["# MNIST Classification with DNN"]},{"cell_type":"code","metadata":{"id":"EBxGFgCPW8yX","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"euSSgznuW8yk","colab_type":"code","colab":{}},"source":["#Reset tensorflow graph\n","tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"grQQ6bERW8yu","colab_type":"text"},"source":["Step 1 : Collect Data"]},{"cell_type":"code","metadata":{"id":"OgZl0Q0GW8yv","colab_type":"code","outputId":"1c1a68e4-3d71-46d7-c414-472c18aa128b","executionInfo":{"status":"ok","timestamp":1569176480711,"user_tz":-330,"elapsed":9870,"user":{"displayName":"Meenakshi Ramaswamy","photoUrl":"https://lh4.googleusercontent.com/-3sXdlOXrEr8/AAAAAAAAAAI/AAAAAAAACC8/ngMx9EiU3T4/s64/photo.jpg","userId":"09422112087559126593"}},"colab":{"base_uri":"https://localhost:8080/","height":505}},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","mnists = input_data.read_data_sets('MNIST_data')\n","trai = mnists.train.images\n","trt = mnists.train.labels\n","trt[0:1]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-3-cea1a206c578>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([7], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"JuwZdW4vHiDt","colab_type":"code","outputId":"dd567c70-8553-4649-a243-89ab73573ba2","executionInfo":{"status":"ok","timestamp":1569176480717,"user_tz":-330,"elapsed":8017,"user":{"displayName":"Meenakshi Ramaswamy","photoUrl":"https://lh4.googleusercontent.com/-3sXdlOXrEr8/AAAAAAAAAAI/AAAAAAAACC8/ngMx9EiU3T4/s64/photo.jpg","userId":"09422112087559126593"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["trai"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"26dnFyNt0ego","colab_type":"code","outputId":"c8fa122e-5a4a-4597-cee6-eff3ed103490","executionInfo":{"status":"ok","timestamp":1569176480720,"user_tz":-330,"elapsed":5078,"user":{"displayName":"Meenakshi Ramaswamy","photoUrl":"https://lh4.googleusercontent.com/-3sXdlOXrEr8/AAAAAAAAAAI/AAAAAAAACC8/ngMx9EiU3T4/s64/photo.jpg","userId":"09422112087559126593"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["trai.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(55000, 784)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"qmo5OKEcW8y1","colab_type":"code","outputId":"74bd125a-3a87-45ca-e640-3049b7f3c3ea","executionInfo":{"status":"ok","timestamp":1569176481457,"user_tz":-330,"elapsed":4619,"user":{"displayName":"Meenakshi Ramaswamy","photoUrl":"https://lh4.googleusercontent.com/-3sXdlOXrEr8/AAAAAAAAAAI/AAAAAAAACC8/ngMx9EiU3T4/s64/photo.jpg","userId":"09422112087559126593"}},"colab":{"base_uri":"https://localhost:8080/","height":159}},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TKFJeMxHW8y7","colab_type":"code","outputId":"3a06aea9-46bf-4a6f-f7d9-d4346ff8cf97","executionInfo":{"status":"ok","timestamp":1569176486996,"user_tz":-330,"elapsed":1503,"user":{"displayName":"Meenakshi Ramaswamy","photoUrl":"https://lh4.googleusercontent.com/-3sXdlOXrEr8/AAAAAAAAAAI/AAAAAAAACC8/ngMx9EiU3T4/s64/photo.jpg","userId":"09422112087559126593"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["mnist"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f37ea430320>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f37ea430080>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f37ea430470>)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"MUuvfLfwW8zA","colab_type":"text"},"source":["Step 1a : Get Training and Test Data"]},{"cell_type":"code","metadata":{"id":"hGMiIygDW8zB","colab_type":"code","colab":{}},"source":["trainX = mnist.train.images\n","trainY = mnist.train.labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tSgGLXhjW8zH","colab_type":"code","colab":{}},"source":["testX = mnist.test.images\n","testY = mnist.test.labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ttHVMQMfW8zK","colab_type":"text"},"source":["How many Training and Test Examples?"]},{"cell_type":"code","metadata":{"id":"oe_4TBXbW8zK","colab_type":"code","outputId":"8e2171ff-ad64-43c3-e512-2ee9bf8dffd9","executionInfo":{"status":"ok","timestamp":1569176499561,"user_tz":-330,"elapsed":1310,"user":{"displayName":"Meenakshi Ramaswamy","photoUrl":"https://lh4.googleusercontent.com/-3sXdlOXrEr8/AAAAAAAAAAI/AAAAAAAACC8/ngMx9EiU3T4/s64/photo.jpg","userId":"09422112087559126593"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["trainY[0:1]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"lY6qII48i5j2","colab_type":"code","outputId":"cadf97ab-648b-40d9-e08f-e16553a37bc2","executionInfo":{"status":"ok","timestamp":1569176502962,"user_tz":-330,"elapsed":1264,"user":{"displayName":"Meenakshi Ramaswamy","photoUrl":"https://lh4.googleusercontent.com/-3sXdlOXrEr8/AAAAAAAAAAI/AAAAAAAACC8/ngMx9EiU3T4/s64/photo.jpg","userId":"09422112087559126593"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["#dic of values for defining LR value and the batch size\n","#Dictionary  {0.001: 200, 0.003: 250, 0.015: 150, 0.05: 300, 0.2: 275}\n","dict_lrsb = dict([(0.3, 200),(0.8,250),(0.015,150),(0.05,300),(0.2,275)])\n","print ('Dictionary ',dict_lrsb)\n","print ('Learning Rate : ',dict_lrsb.keys())\n","print ('Batch Size : ',dict_lrsb.values())\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dictionary  {0.3: 200, 0.8: 250, 0.015: 150, 0.05: 300, 0.2: 275}\n","Learning Rate :  dict_keys([0.3, 0.8, 0.015, 0.05, 0.2])\n","Batch Size :  dict_values([200, 250, 150, 300, 275])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LuAcPbcSqEGo","colab_type":"code","colab":{}},"source":["from collections import defaultdict\n"," \n","my_default_dict = defaultdict(list)\n"," \n","# Lets add 10 values to \"My Key\"\n","for i in range(5):\n"," #print dict_lrsb[i] \n"," learning_rate = (list(dict_lrsb)[i])\n"," print (learning_rate)\n"," print (dict_lrsb[learning_rate])\n"," #print (list(dict_lrsb.values()[i]))\n"," #my_default_dict[\"My Key\"].append(i)\n"," \n","#print(my_default_dict[\"My Key\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0qqy5Gbk6_K","colab_type":"code","colab":{}},"source":["for key,value in dict_lrsb.items():\n","  print ( 'LR : ',key  ,': Batch Sz ', value)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vrTeJLiTW8zN","colab_type":"text"},"source":["Lets define some parameters"]},{"cell_type":"code","metadata":{"id":"VeExHZ_qW8zN","colab_type":"code","colab":{}},"source":["logs_path = \"/content/\"\n","#learning_rate = 0.2\n","n_features = trainX.shape[1]\n","n_classes = trainY.shape[1]\n","model_name = 'mnist.ckpt'\n","\n","#How many examples to feed for training at one time\n","#batch_size = 200\n","\n","#How many times all the data to be shown\n","training_epochs = 250\n","\n","J = 522\n","K = 340\n","L = 230\n","M = 150\n","N = 100\n","O = 66\n","P = 44\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3ko7F6yIcjA","colab_type":"code","outputId":"5b4b936c-3848-4a4d-88c5-627f8f6a4d49","executionInfo":{"status":"ok","timestamp":1569176517645,"user_tz":-330,"elapsed":1229,"user":{"displayName":"Meenakshi Ramaswamy","photoUrl":"https://lh4.googleusercontent.com/-3sXdlOXrEr8/AAAAAAAAAAI/AAAAAAAACC8/ngMx9EiU3T4/s64/photo.jpg","userId":"09422112087559126593"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["n_classes"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"vuhlSnbrW8zP","colab_type":"text"},"source":["# Build the Graph"]},{"cell_type":"markdown","metadata":{"id":"kk1McFvRW8zP","colab_type":"text"},"source":["Input placeholders"]},{"cell_type":"code","metadata":{"id":"c7JoZ9Yf8-0Q","colab_type":"code","colab":{}},"source":["for key,value in dict_lrsb.items():\n","  print ( 'LR : ',key  ,': Batch Sz ', value)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WeqbqBXCqvUh","colab_type":"code","outputId":"beb2b44e-c751-4b40-8170-9b722dd8f78e","executionInfo":{"status":"ok","timestamp":1569177786254,"user_tz":-330,"elapsed":1266590,"user":{"displayName":"Meenakshi Ramaswamy","photoUrl":"https://lh4.googleusercontent.com/-3sXdlOXrEr8/AAAAAAAAAAI/AAAAAAAACC8/ngMx9EiU3T4/s64/photo.jpg","userId":"09422112087559126593"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for a in range(5):\n","\n","  learning_rate = (list(dict_lrsb)[a])\n","  #print (learning_rate)\n","  batch_size = (dict_lrsb[learning_rate])\n","  #print (batch_size)\n","  print (\"Learing Rate, Batch Size : \", learning_rate ,batch_size )\n","\n","  with tf.name_scope('input'):\n","    # None -> batch size can be any size, with n_features\n","    x = tf.placeholder(tf.float32, shape=[None, n_features], name=\"x-input\") \n","    # target n_classes output classes\n","    y_ = tf.placeholder(tf.float32, shape=[None, n_classes], name=\"y-input\")\n","    \n","  with tf.name_scope('layer_1'):\n","    W1 = tf.Variable(tf.truncated_normal([n_features, J], stddev=0.1))\n","    b1 = tf.Variable(tf.zeros([J]))\n","    Y1 = tf.nn.sigmoid(tf.add(tf.matmul(x,W1),b1)) ## Y1 becomes the new x in the next iteration\n","  \n","  with tf.name_scope('layer_2'):\n","    W2 = tf.Variable(tf.truncated_normal([J, K], stddev=0.1))\n","    b2 = tf.Variable(tf.zeros([K]))\n","    Y2 = tf.nn.sigmoid(tf.add(tf.matmul(Y1,W2),b2))\n","  \n","  with tf.name_scope('layer_3'):\n","    W3 = tf.Variable(tf.truncated_normal([K, L], stddev=0.1))\n","    b3 = tf.Variable(tf.zeros([L]))\n","    Y3 = tf.nn.sigmoid(tf.add(tf.matmul(Y2,W3),b3))\n","    \n","  with tf.name_scope('layer_4'):\n","    W4 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n","    b4 = tf.Variable(tf.zeros([M]))\n","    Y4 = tf.nn.sigmoid(tf.add(tf.matmul(Y3,W4),b4))\n","  \n","  with tf.name_scope('layer_5'):\n","    W5 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\n","    b5 = tf.Variable(tf.zeros([N]))\n","    Y5 = tf.nn.sigmoid(tf.add(tf.matmul(Y4,W5),b5))\n","    \n","  with tf.name_scope('layer_6'):\n","    W6 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1))\n","    b6 = tf.Variable(tf.zeros([O]))\n","    Y6 = tf.nn.sigmoid(tf.add(tf.matmul(Y5,W6),b6))\n","  \n","  with tf.name_scope('layer_7'):\n","    W5 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\n","    b5 = tf.Variable(tf.zeros([N]))\n","    Y5 = tf.nn.sigmoid(tf.add(tf.matmul(Y4,W5),b5))\n","    \n","  with tf.name_scope(\"Output\"):\n","    W6 = tf.Variable(tf.truncated_normal([N,n_classes], stddev=0.1))\n","    b6 = tf.Variable(tf.zeros([n_classes]))\n","    y = tf.nn.softmax(tf.matmul(Y5,W6) + b6)\n","  \n","  with tf.name_scope('Loss'):\n","    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n","  \n","  with tf.name_scope('train'):        \n","    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)    ####LR\n","    \n","  with tf.name_scope('Accuracy'):\n","    prediction = tf.argmax(y,1,name=\"Predict\")    \n","    correct_prediction = tf.equal(prediction, tf.argmax(y_,1))\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"accuracy\")  \n","    \n"," # create a summary for our cost and accuracy\n","  training_loss = tf.summary.scalar(\"training_loss\", cross_entropy)\n","  training_accuracy = tf.summary.scalar(\"training_accuracy\", accuracy)\n","  test_loss = tf.summary.scalar(\"test_loss\", cross_entropy)\n","  test_accuracy = tf.summary.scalar(\"test_accuracy\", accuracy)\n","  \n","  #Create a Saver to save the graph\n","  saver = tf.train.Saver()\n","  \n","  #Start Graph execution\n","  with tf.Session() as sess:\n","   # variables need to be initialized before we can use them\n","      sess.run(tf.global_variables_initializer())\n","\n","      # create log writer object\n","      writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n","\n","      # perform training cycles\n","      for epoch in range(training_epochs):\n","        \n","        # number of batches in one epoch\n","        batch_count = int(trainX.shape[0]/batch_size)\n","    \n","    \n","        for i in range(batch_count):\n","            batch_x  = trainX[i*batch_size:i*batch_size+batch_size]\n","            batch_y  = trainY[i*batch_size:i*batch_size+batch_size]\n","\n","            # perform the operations we defined earlier on batch\n","            _,acc,loss = sess.run([train_op, training_accuracy,training_loss], feed_dict={x: batch_x, y_: batch_y})\n","            \n","            #log training accuracy and loss\n","            writer.add_summary(acc, epoch * batch_count + i)\n","            writer.add_summary(loss, epoch * batch_count + i)    \n","                       \n","      #Test loss and accuracy\n","        #pls note we are giving test data\n","        acc,loss = sess.run([test_accuracy,test_loss],feed_dict={x: testX, y_: testY})\n","        writer.add_summary(acc, epoch * batch_count + i)\n","        writer.add_summary(loss, epoch * batch_count + i)\n","        \n","        if epoch % 25 == 0: \n","            print (\"Epoch: \", epoch)\n","            print (\"Test Accuracy: \", accuracy.eval(feed_dict={x: testX, y_: testY}))               \n","    \n","    \n","    #Save the model\n","      writer = tf.summary.FileWriter('./graphs', sess.graph)\n","      saver.save(sess, logs_path + '/' + model_name)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Learing Rate, Batch Size :  0.3 200\n","Epoch:  0\n","Test Accuracy:  0.0958\n","Epoch:  25\n","Test Accuracy:  0.9574\n","Epoch:  50\n","Test Accuracy:  0.9718\n","Epoch:  75\n","Test Accuracy:  0.9734\n","Epoch:  100\n","Test Accuracy:  0.9726\n","Epoch:  125\n","Test Accuracy:  0.975\n","Epoch:  150\n","Test Accuracy:  0.9756\n","Epoch:  175\n","Test Accuracy:  0.9755\n","Epoch:  200\n","Test Accuracy:  0.9759\n","Epoch:  225\n","Test Accuracy:  0.9756\n","Learing Rate, Batch Size :  0.8 250\n","Epoch:  0\n","Test Accuracy:  0.0958\n","Epoch:  25\n","Test Accuracy:  0.9719\n","Epoch:  50\n","Test Accuracy:  0.9755\n","Epoch:  75\n","Test Accuracy:  0.976\n","Epoch:  100\n","Test Accuracy:  0.9781\n","Epoch:  125\n","Test Accuracy:  0.9785\n","Epoch:  150\n","Test Accuracy:  0.9794\n","Epoch:  175\n","Test Accuracy:  0.9794\n","Epoch:  200\n","Test Accuracy:  0.9793\n","Epoch:  225\n","Test Accuracy:  0.9796\n","Learing Rate, Batch Size :  0.015 150\n","Epoch:  0\n","Test Accuracy:  0.1028\n","Epoch:  25\n","Test Accuracy:  0.1028\n","Epoch:  50\n","Test Accuracy:  0.3865\n","Epoch:  75\n","Test Accuracy:  0.6831\n","Epoch:  100\n","Test Accuracy:  0.851\n","Epoch:  125\n","Test Accuracy:  0.8942\n","Epoch:  150\n","Test Accuracy:  0.9187\n","Epoch:  175\n","Test Accuracy:  0.9309\n","Epoch:  200\n","Test Accuracy:  0.9448\n","Epoch:  225\n","Test Accuracy:  0.9521\n","Learing Rate, Batch Size :  0.05 300\n","Epoch:  0\n","Test Accuracy:  0.1028\n","Epoch:  25\n","Test Accuracy:  0.2759\n","Epoch:  50\n","Test Accuracy:  0.772\n","Epoch:  75\n","Test Accuracy:  0.8965\n","Epoch:  100\n","Test Accuracy:  0.9231\n","Epoch:  125\n","Test Accuracy:  0.9392\n","Epoch:  150\n","Test Accuracy:  0.9517\n","Epoch:  175\n","Test Accuracy:  0.9593\n","Epoch:  200\n","Test Accuracy:  0.9638\n","Epoch:  225\n","Test Accuracy:  0.9668\n","Learing Rate, Batch Size :  0.2 275\n","Epoch:  0\n","Test Accuracy:  0.0958\n","Epoch:  25\n","Test Accuracy:  0.914\n","Epoch:  50\n","Test Accuracy:  0.9615\n","Epoch:  75\n","Test Accuracy:  0.9705\n","Epoch:  100\n","Test Accuracy:  0.9722\n","Epoch:  125\n","Test Accuracy:  0.9751\n","Epoch:  150\n","Test Accuracy:  0.9756\n","Epoch:  175\n","Test Accuracy:  0.9748\n","Epoch:  200\n","Test Accuracy:  0.975\n","Epoch:  225\n","Test Accuracy:  0.9766\n"],"name":"stdout"}]}]}